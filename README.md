# Local AI Chat App

このアプリは、AIチャットツールです。

## 1. 必要なソフトウェア
アプリを動かすために、以下の2つを事前にインストールしてください。

- **Ollama**: AIモデルを動かすためのエンジン  
  [公式サイト](https://ollama.com/)からダウンロードしてください。
- **Python (3.9以上)**: 橋渡し役（APIサーバ）を動かすためのプログラミング言語。

## 2. AIモデルの準備
Ollamaがインストールされた状態で、ターミナル（コマンドプロンプトやPowerShell）を開き、以下のコマンドを入力してAIモデルをダウンロードします。

```bash
ollama pull gemma3:4b

```

## 3. ライブラリのインストール

APIサーバを動かすために必要なライブラリをインストールします。

```bash
pip install fastapi uvicorn requests

```

## 4. アプリの起動・操作方法

1. **サーバを起動する**:
本リポジトリのファイルがあるディレクトリで、以下のコマンドを実行します。
```bash
uvicorn main:app --reload

```


2. **ブラウザでアクセスする**:
[http://127.0.0.1:8000](http://127.0.0.1:8000) にアクセスします。
3. **チャットを開始する**:
入力欄にメッセージを入れて「送信」を押すと、AIが返答を開始します。

## 5. 技術的な仕組み

* **フロントエンド**: HTML/JavaScriptを使用。`fetch API` と `ReadableStream` を使い、AIの回答を1文字ずつリアルタイムに表示（ストリーミング）します。
* **バックエンド**: `FastAPI` を採用。ローカルで動く `Ollama API` へリクエストを転送します。
* **AIモデル**: `Gemma 3 (4b)` を使用。ローカルPCのCPU/GPUリソースのみで推論を行います。
